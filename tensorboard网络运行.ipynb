{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting minist_data\\train-images-idx3-ubyte.gz\n",
      "Extracting minist_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting minist_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting minist_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#导入数据集\n",
    "minist = input_data.read_data_sets(\"minist_data\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#每个批次的大小\n",
    "batch_size = 100\n",
    "#计算一共有多少个批次\n",
    "n_batch = minist.train.num_examples//batch_size\n",
    "\n",
    "#参数概要\n",
    "def variable_summares(var):\n",
    "    with tf.name_scope(\"summares\"):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar(\"mean\",mean)#平均值\n",
    "        with tf.name_scope(\"stddev\"):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar(\"stddev\",stddev)#标准差\n",
    "        tf.summary.scalar(\"max\",tf.reduce_max(var))#最大值\n",
    "        tf.summary.scalar(\"min\",tf.reduce_min(var))#最小值\n",
    "        tf.summary.histogram(\"histogram\",var)\n",
    "        \n",
    "#打定义占位符\n",
    "with tf.name_scope(\"input\"):\n",
    "    x = tf.placeholder(tf.float32,[None,784],name=\"x_input\")\n",
    "    y = tf.placeholder(tf.float32,[None,10],name=\"y_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建简单网路\n",
    "with tf.name_scope(\"layers\"):\n",
    "    with tf.name_scope(\"weights\"):\n",
    "        w = tf.Variable(tf.zeros([784,10]),name=\"w\")\n",
    "        variable_summares(w)\n",
    "    with tf.name_scope(\"biases\"):\n",
    "        b = tf.Variable(tf.zeros([10]),name=\"b\")\n",
    "        variable_summares(b)\n",
    "    with tf.name_scope(\"w_plus_b\"):\n",
    "        w_plus_b = tf.matmul(x,w)+b\n",
    "    with tf.name_scope(\"softmax\"):\n",
    "        prediction = tf.nn.softmax(w_plus_b)\n",
    "\n",
    "#定义代价函数\n",
    "# loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y,logits=prediction))#交叉熵\n",
    "    tf.summary.scalar(\"loss\",loss)\n",
    "\n",
    "#使用梯度下降\n",
    "with tf.name_scope(\"train\"):\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "#初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "#结果存放在bool型列表中\n",
    "correct_prediction = tf.equal(tf.math.argmax(y,1),tf.math.argmax(prediction,1))\n",
    "#求准确率\n",
    "with tf.name_scope(\"accuary\"):\n",
    "    accuary = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    tf.summary.scalar(\"accuary\",accuary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter0,Testing Accuary0.7735\n",
      "Iter1,Testing Accuary0.8053\n",
      "Iter2,Testing Accuary0.8154\n",
      "Iter3,Testing Accuary0.8215\n",
      "Iter4,Testing Accuary0.8257\n",
      "Iter5,Testing Accuary0.828\n",
      "Iter6,Testing Accuary0.8577\n",
      "Iter7,Testing Accuary0.8751\n",
      "Iter8,Testing Accuary0.8844\n",
      "Iter9,Testing Accuary0.8933\n",
      "Iter10,Testing Accuary0.8958\n",
      "Iter11,Testing Accuary0.8976\n",
      "Iter12,Testing Accuary0.8983\n",
      "Iter13,Testing Accuary0.8997\n",
      "Iter14,Testing Accuary0.9013\n",
      "Iter15,Testing Accuary0.9026\n",
      "Iter16,Testing Accuary0.9037\n",
      "Iter17,Testing Accuary0.9042\n",
      "Iter18,Testing Accuary0.905\n",
      "Iter19,Testing Accuary0.906\n",
      "Iter20,Testing Accuary0.9062\n",
      "Iter21,Testing Accuary0.9074\n",
      "Iter22,Testing Accuary0.9075\n",
      "Iter23,Testing Accuary0.9084\n",
      "Iter24,Testing Accuary0.9091\n",
      "Iter25,Testing Accuary0.9092\n",
      "Iter26,Testing Accuary0.9091\n",
      "Iter27,Testing Accuary0.909\n",
      "Iter28,Testing Accuary0.9095\n",
      "Iter29,Testing Accuary0.9095\n",
      "Iter30,Testing Accuary0.91\n",
      "Iter31,Testing Accuary0.9101\n",
      "Iter32,Testing Accuary0.9108\n",
      "Iter33,Testing Accuary0.9112\n",
      "Iter34,Testing Accuary0.9116\n",
      "Iter35,Testing Accuary0.9119\n",
      "Iter36,Testing Accuary0.9124\n",
      "Iter37,Testing Accuary0.912\n",
      "Iter38,Testing Accuary0.9132\n",
      "Iter39,Testing Accuary0.9132\n",
      "Iter40,Testing Accuary0.9134\n",
      "Iter41,Testing Accuary0.9145\n",
      "Iter42,Testing Accuary0.9137\n",
      "Iter43,Testing Accuary0.9144\n",
      "Iter44,Testing Accuary0.9156\n",
      "Iter45,Testing Accuary0.9147\n",
      "Iter46,Testing Accuary0.9153\n",
      "Iter47,Testing Accuary0.9154\n",
      "Iter48,Testing Accuary0.9157\n",
      "Iter49,Testing Accuary0.9162\n",
      "Iter50,Testing Accuary0.9169\n",
      "Iter51,Testing Accuary0.9168\n",
      "Iter52,Testing Accuary0.9172\n",
      "Iter53,Testing Accuary0.9172\n",
      "Iter54,Testing Accuary0.9173\n",
      "Iter55,Testing Accuary0.9176\n",
      "Iter56,Testing Accuary0.9176\n",
      "Iter57,Testing Accuary0.9179\n",
      "Iter58,Testing Accuary0.918\n",
      "Iter59,Testing Accuary0.9183\n"
     ]
    }
   ],
   "source": [
    "#合并所有的summary\n",
    "merged = tf.summary.merge_all()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "    for epoch in range(60):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = minist.train.next_batch(batch_size)\n",
    "            summary,_ = sess.run([merged,train_step],feed_dict={x:batch_xs,y:batch_ys})\n",
    "        writer.add_summary(summary,epoch)  \n",
    "        acc = sess.run(accuary,feed_dict={x:minist.test.images,y:minist.test.labels})\n",
    "            \n",
    "        print('Iter'+str(epoch)+\",Testing Accuary\"+str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
